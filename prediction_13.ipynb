{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依赖：\n",
    "# !pip install sentencepiece\n",
    "# !pip install jieba\n",
    "# !pip install regex\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "from tokenization_jieba import JIEBATokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.0\n"
     ]
    }
   ],
   "source": [
    "print(hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = JIEBATokenizer(\n",
    "    'PanGu-Alpha-GPU/panguAlpha_pytorch/megatron/tokenizer/bpe_4w_pcl/vocab.vocab',\n",
    "    'PanGu-Alpha-GPU/panguAlpha_pytorch/megatron/tokenizer/bpe_4w_pcl/vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = hub.load('./pangu-13B-tf2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(tokenizer, gpt, sentence, number=1, length=20, top_k=50, top_p=0.9, temperature=0.9):\n",
    "    \"\"\"\n",
    "    numbert: 输出句子个数\n",
    "    length: 输出最大长度\n",
    "    top_k: 只选择前k个，如果为0则为无限制\n",
    "    top_p: token的概率排在这以上才有效\n",
    "    temperature: 温度，如果为1.0则相当于无效\n",
    "    \"\"\"\n",
    "    inputs = tf.constant([tokenizer.encode(sentence)] * number, dtype=tf.int64)\n",
    "    length = tf.constant(length, dtype=tf.int64)\n",
    "    ret = gpt.signatures['serving_default'](\n",
    "        inp=inputs,\n",
    "        length=length,\n",
    "        top_k=tf.constant(top_k, tf.int32),\n",
    "        top_p=tf.constant(top_p, tf.float32),\n",
    "        temperature=tf.constant(temperature, tf.float32)\n",
    "    )['output_0']\n",
    "    return [\n",
    "        tokenizer.decode([int(x) for x in s]).replace(' ', '')\n",
    "        for s in ret.numpy()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt(question):\n",
    "    q = f'''\n",
    "问题：中国首都是哪里？\n",
    "答案：北京\n",
    "问题：美国的首都是哪里？\n",
    "答案：华盛顿\n",
    "问题：李白在哪个朝代？\n",
    "答案：唐朝\n",
    "问题：{question}\n",
    "答案：'''\n",
    "    ret = sample(tokenizer, gpt, q, 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "    answers = []\n",
    "    for x in ret:\n",
    "        a = x[len(q):]\n",
    "        a = a.split('\\n')[0]\n",
    "        answers.append(a)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.563 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['明代', '明朝', '明朝']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('唐伯虎是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['布拉德皮特', '贝克汉姆', '美国总统里根']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最帅的是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['爱因斯坦', '爱因斯坦', '哥伦布']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最聪明的人是谁？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['宋朝', '北宋', '宋朝']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('李清照是哪个朝代的人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['关羽', '关羽', '秦琼']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('关公和秦琼谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['把一百元的东西放到地上,然后去掉', '去赌场', '每天去一家公司工作八小时,每小时赚']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何赚一百万美元？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['烧烤', '烧烤', '烧烤']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烧烤和火锅哪个好吃？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['拜师学艺', '考试', '先当学生,再当老师。']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('如何成为老师？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['袋鼠', '熊猫', '猩猩']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('佩奇是什么动物？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['八条', '四条腿', '四条腿']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('大象有几条腿？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['姚明1米88', '2米26', '2米26']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('姚明有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['杰瑞', '杰瑞', '杰瑞']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('汤姆和杰瑞谁厉害？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['能', '当然。', '能']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('野原新之助能打过樱桃子吗？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['学音乐', '学音乐好', '音乐']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('学音乐和学画画哪个好？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中文', '中文', '中文']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中文和英文哪个难学？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python', 'java<eot>', 'java']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('python和java哪个难？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['趁着这棵树刚刚发芽。', '谁知盘中餐,粒粒皆辛苦', '谁知盘中餐,粒粒皆辛苦']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('“锄禾日当午”的下一句是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['鲜鸭肉', '鸭毛', '鸭肉']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('烤鸭的主要原料是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['把大象放冰箱之前要做什么?', '两步', '一步<eot>问题:最长的一条被子有多']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('把大象放冰箱总共分几步？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8848米', '8844.43米', '8848米']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('珠穆朗玛峰有多高？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['珠穆朗玛峰', '珠穆朗玛峰', '珠穆朗玛峰']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('世界上最高的山是什么？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3亿', '中国人口总数为13亿', '3亿人']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('中国有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一亿以上', '33.3', '大约20人']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('日本有多少人？')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['苹果', '华为手机好', '华为手机好']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_gpt('苹果手机好还是华为手机好？')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小明。\n",
      "小明说:“你自己去\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小明<eot>为什么中国男人这么优秀\n",
      "这话\n",
      "--------------------\n",
      "小明决定去吃饭,小红继续写作业\n",
      "问题:去吃饭的人是谁?\n",
      "答案:小明<eot>为什么我的电脑老是死机,重装\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '小明决定去吃饭，小红继续写作业\\n问题：去吃饭的人是谁？\\n答案：', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文问答例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟duck\n",
      "鱼noodle\n",
      "马\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟birds\n",
      "牛bull\n",
      "马\n",
      "--------------------\n",
      "默写英文:\n",
      "狗dog\n",
      "猫cat\n",
      "鸟chicken\n",
      "猴puppy\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写英文：\\n狗dog\\n猫cat\\n鸟', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 默写古诗例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "2、写出你\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望明\n",
      "--------------------\n",
      "默写古诗:\n",
      "白日依山尽,黄河入海流。\n",
      "床前明月光,疑是地上霜。\n",
      "举头望明\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '默写古诗：\\n白日依山尽，黄河入海流。\\n床前明月光，', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不同的角色对话生成例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“小兔崽子!你眼里还有没有我这个老佟!”\n",
      "李大\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“我的个乖乖,您今儿是怎么了?”\n",
      "李大嘴:“我\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "佟掌柜:“李大嘴,你还真叫人难找啊!”\n",
      "李大嘴:“\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n佟掌柜：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“李大嘴!”\n",
      "李大嘴:“展堂!”\n",
      "白\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“我看你最好还是和小李一起去找他妈妈!”\n",
      "李大\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "白展堂:“哎哟,您别走啊,您别走啊!”\n",
      "冯西\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n白展堂：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“李大嘴你别这样!”\n",
      "李大嘴:“莫小贝,你别\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“各回各家,各找各妈!”\n",
      "李大嘴:“有我呢\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "莫小贝:“大家听我说,我们现在是一条船上的人,不能再分开了。大家\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n莫小贝：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“你可真坏!”\n",
      "李大嘴:“就我坏,就我坏\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“我有!”\n",
      "李大嘴:“我有!”\n",
      "李白\n",
      "--------------------\n",
      "李大嘴:“各回各家,各找各妈!”\n",
      "李白:“我看你是没脸见人了!”\n",
      "李大嘴:“我这\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李大嘴：“各回各家，各找各妈！” \\n李白：“', 3, 20, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问答的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "中国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "英国\n",
      "--------------------\n",
      "中国的首都是北京\n",
      "日本的首都是东京\n",
      "美国的首都是华盛顿\n",
      "法国\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '中国的首都是北京\\n日本的首都是东京\\n美国的首都是', 3, 3, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明\n",
      "--------------------\n",
      "李白所在朝代是唐\n",
      "李清照所在朝代是宋\n",
      "唐伯虎所在朝代是明代\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '李白所在朝代是唐\\n李清照所在朝代是宋\\n唐伯虎所在朝代是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n",
      "陈奕迅是歌星\n",
      "郭德纲是相声演员\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '陈奕迅是歌星\\n郭德纲是', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "珠穆朗玛峰的高度(米)是4,880,0(5,337\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是7,287<eot>珠穆朗玛峰高度\n",
      "--------------------\n",
      "珠穆朗玛峰的高度(米)是6,746,4,430<eot>珠\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '珠穆朗玛峰的高度（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "姚明的身高(米)是多少\n",
      "姚明身高是2.26米<eot>和\n",
      "--------------------\n",
      "姚明的身高(米)是2.01M<eot>姚明的身高(米)是\n",
      "--------------------\n",
      "姚明的身高(米)是多少\n",
      "姚明身高是2.26米<eot>姚明\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '姚明的身高（米）是', 3, 10, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 算数例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=9\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=9\n",
      "--------------------\n",
      "1+1=2\n",
      "2+2=4\n",
      "3+3=6\n",
      "4+4=8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n2+2=4\\n3+3=6\\n4+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=6\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=6\n",
      "--------------------\n",
      "1+1=2\n",
      "1+2=3\n",
      "1+3=4\n",
      "1+4=8\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '1+1=2\\n1+2=3\\n1+3=4\\n1+4=', 3, 1, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ???的例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "黑光这\n",
      "黑光这黑光这黑光这黑光这黑光这黑光这黑光这黑光这黑光\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "雷罚天渊之雷\n",
      "天灵地怒焚天\n",
      "天劫雷霆怒\n",
      "雷之极威\n",
      "雷之极罚\n",
      "--------------------\n",
      "惊雷这通天修为\n",
      "天塌地陷紫金锤\n",
      "紫电这玄真火焰\n",
      "这就是境界\n",
      "我说的是境界啊,惊雷是境界<eot>有多忙\n",
      "有一个人\n",
      "人\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''惊雷这通天修为\n",
    "天塌地陷紫金锤\n",
    "紫电这玄真火焰\n",
    "''', 3, 30, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写作文例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱情是什么?\n",
      "爱是一种感觉,是无法说出的感觉,爱是愉快,是难过,是陶醉,是情绪,是勇敢,是信赖,是诚意,是体贴,\n",
      "--------------------\n",
      "爱情是糖,甜到忧伤\n",
      "这一刻我感到忧伤,原来爱情会给我糖吃<eot>爱情是糖,甜到忧伤,爱情是糖,甜到忧伤!如果说爱情是一种信仰,那么爱情信仰\n",
      "--------------------\n",
      "爱情是个什么玩意儿\n",
      "爱情是你想有就有,想爱就爱,想去就去<eot>爱情是你想有就有,想爱就爱,想去就去爱情是你想有就有,想爱\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(tokenizer, gpt, '''爱情是''', 3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。因命紫鹃取钥匙开了仪门,从甬路穿过正院,便进了北向的三间小偏房。两边房门上各有金字横匾,是“蕙兰香芷”四字。那东边一间,也是紫鹃开的,上边⁇了一个“寿”字,两旁配着对联,却是\"金满池塘\"。黛玉便知这方是专给宝玉安身的,又是个小书房,因指给紫鹃看,说:“你看,他是宝玉的书斋。”那紫鹃见黛玉言语温存,十分欢喜,便忙沏了茶来。<eot>本公司提供北京房产按揭贷款服务,北京房产按揭贷款申请条件,北京房产按揭贷款流程,北京房产按揭贷款服务,北京房产按揭贷款资料,北京房产按揭贷款\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。只听得里面脚步声响,又见两个丫头出来,俱穿着金钏银镯,一个打扮的如牡丹花下芍药,一个打扮的如芙蓉花上芙蓉,走将出来,笑道:“这是谁?好标致!”黛玉忙上前见礼,口内低言:“这是我那大妹子,昨儿晚上,在我这里吃酒,被风吹倒了,也不知道是怎么回事。”那两个小丫头便笑道:“太太说,大姐姐是二姐姐的亲妹子,这两位姐姐才是亲姊妹呢。”黛玉听了,虽也是个大家小姐,毕竟年小,心里颇不自在,见那两个小丫头和两个小丫头站在两边,便向黛玉耳边低低说了几句话,黛玉笑道:“我竟不知你们。”那两个小丫头道:“那是二\n",
      "--------------------\n",
      "一时黛玉进了荣府,下了车。众嬷嬷引着,便往东转弯,穿过一个东西的穿堂,向南大厅之后,仪门内大院落,上面五间大正房,两边厢房鹿顶耳房钻山,四通八达,轩昂壮丽,比贾母处不同。黛玉便知这方是正经正内室,一条大甬路,直接出大门的。到了二门口,早有妥当的太监,引着黛玉进了里面的大门,从仪门至东一顺台阶。这是正房,两扇朱漆大门,上有金字匾额,写着“怡红院”三个大字。黛玉正想着,忽见一个太监,引着两个人,从仪门进来,这两个人,一个是宝钗,一个是黛玉。宝玉一见,便笑道:“原来是你两个,来这里做什么?”宝钗笑道:“我从东边来,走到这里,看见你两个来了,我要躲,偏偏走到这里来了。”宝玉道:“既是这样,进来吧。”二人进了大门,只见东西两边,摆了许多小床小桌小椅,又有几案几凳,还有一个屏风,挂着一幅山水,画的是荷花、菱角、\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''一时黛玉进了荣府，下了车。众嬷嬷引着，便往东转弯，穿过一个东西的穿堂，向南大厅之后，仪门内大院落，上面五间大正房，两边厢房鹿顶耳房钻山，四通八达，轩昂壮丽，比贾母处不同。黛玉便知这方是正经正内室，一条大甬路，直接出大门的。''',\n",
    "    3, 200, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“今天我想吃火锅”\n",
      "B:“我想吃披萨”\n",
      "A:“我想吃辣炒年糕”\n",
      "B:“我想吃咖喱牛肉”\n",
      "A:“我想吃龙虾”\n",
      "B:“我想吃披萨”\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“今天我想吃火锅”\n",
      "C:“今天我想吃火锅”\n",
      "D:“今天我想吃火锅”\n",
      "2.下列句子中,没有语病的一句是()\n",
      "A:从前\n",
      "--------------------\n",
      "A:“今天我想吃火锅”\n",
      "B:“今天我想吃烤鱼”\n",
      "C:“今天我想吃汉堡”\n",
      "D:“今天我想吃披萨”\n",
      "E:“今天我想吃臭豆腐”\n",
      "F:“今天我想吃\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    '''A：“今天我想吃火锅”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:“跟我一起去看电影吧”\n",
      "B:“好啊,但是我要换一部”\n",
      "A:“好吧,那换一部吧”\n",
      "B:“好的,太好了”\n",
      "A:“喂,你的耳朵啊,还没好啊?”\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“想看什么电影?”\n",
      "A:“想看《我爱我家》,你陪我一起去吧。”\n",
      "B:“哦,好吧。”\n",
      "A:“《我爱我家》是\n",
      "--------------------\n",
      "A:“跟我一起去看电影吧”\n",
      "B:“你喜欢看恐怖片吗?”\n",
      "A:“你是不是要说我是个变态啊”\n",
      "B:“是的,我觉得你很变态,你可以去看一下,保证你会喜欢的。”\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''A：“跟我一起去看电影吧”\n",
    "B：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对联例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "duilian = '''\n",
    "上联天，下联地\n",
    "上联雨，下联风\n",
    "上联大陆，下联长空\n",
    "上联雷隐隐，下联雾蒙蒙\n",
    "上联开心大吉，下联万事亨通\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联刘禹锡\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联刘禹锡\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联王维写书\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联杜甫吟诗\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联李白作诗,下联苏轼定\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联李白作诗，下联',\n",
    "    5, 2, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联寻找真缘\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联寻找真爱\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联求平安\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联追求幸福\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联追求真爱,下联期待良缘\n",
      "\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联追求真爱，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联日日好运\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联天天快乐\n",
      "上\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联年年进步\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联月月平平\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天天向上,下联夜夜失眠\n",
      "上\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天天向上，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联日月在我梦\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联自然在我门\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联太阳照乾坤\n",
      "\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联太阳在我手\n",
      "--------------------\n",
      "\n",
      "上联天,下联地\n",
      "上联雨,下联风\n",
      "上联大陆,下联长空\n",
      "上联雷隐隐,下联雾蒙蒙\n",
      "上联开心大吉,下联万事亨通\n",
      "上联天地在我心,下联世界在我心\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt,\n",
    "    duilian + '上联天地在我心，下联',\n",
    "    5, 4, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 名人名言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鲁迅曾经说过:“天才就是百分之九十九的汗水加百分之一的灵感”。我想大多数人都没有注意到,这“百分之一”就是他们对待工作的态度。虽然对待工作的态度不同,但是我们作为领导者,对待\n",
      "--------------------\n",
      "鲁迅曾经说过:“在我的周围,是有一种精神的存在。”一个人有什么样的精神,就会有什么样的思想,就会有什么样的行动。一个人拥有怎样的精神,就会形成怎样的性格,就会在日常\n",
      "--------------------\n",
      "鲁迅曾经说过:“中国需要有自己的英雄,有自己的‘精神’。”这句话说出了中国人的价值取向。\n",
      "2018年3月,习近平总书记在“不忘初心、牢记使命”主题教育工作会议上指出\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''鲁迅曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱因斯坦曾经说过:“如果你想找到正确的科学方法,你必须有一个信仰”。没有信仰,你就不可能有正确的方法。作为一名教师,我更愿意告诉家长和学生,科学方法是每个人都应该懂得的,\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“如果一个人能够发现他自己,那么这就是一种解放。”如果一个人能够发现自己,就能使他有可能从经验中不断获得教训,在更高的水平上进行思考。爱因斯坦对此有一句名言\n",
      "--------------------\n",
      "爱因斯坦曾经说过:“我不相信命运,命运在我手中。”\n",
      "命运让你成熟,命运让你坚强,命运让你幸福,\n",
      "命运让你成熟,命运让你坚强,命运让你幸福,\n",
      "没有谁能左右\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''爱因斯坦曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "牛顿曾经说过:“万有引力是最神奇的力,是一个不可捉摸的力,就像电一样。”科学不相信神,但是科学相信你。科学没有什么定律,但科学相信,你就是你,你可以\n",
      "--------------------\n",
      "牛顿曾经说过:“只要你有信心,什么困难都能克服。”\n",
      "“只要你有信心,什么困难都能克服。”在这世界上,每个人都有自己的目标,有的人的目标就是出人头\n",
      "--------------------\n",
      "牛顿曾经说过:“人是理性的生物,是情感的动物。”人类的感情就是情感,一个人生活在社会中,就必然受到社会的影响。而人的这种感情的产生和发展的必然途径是:在生活的过程中\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''牛顿曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "佛祖曾经说过:“不为自己求安乐,但愿众生得离苦。”如果我们把“希望众生得到离苦得乐”当作我们人生的目标,就会心甘情愿、乐而不疲、苦而不厌。反之,如果我们为\n",
      "--------------------\n",
      "佛祖曾经说过:“一粒沙里见世界,一朵花里见天堂。”其实人生也是这样,面对困难,我们总能迎难而上,但在困难面前,也需要坚强,有一种精神叫⁇撼大树,有一种\n",
      "--------------------\n",
      "佛祖曾经说过:“一念为善,一念为恶,直至成佛,为六道众生。”\n",
      "一念之间,善恶有报。一念之差,天堂地狱。\n",
      "佛教认为,世界上有三种人,即\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''佛祖曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "乔布斯曾经说过:“如果你还想重新开始,就做一些新的尝试,然后再重复你已经做过的事情。”我想说,我们每个人都应该去尝试一些新的东西,比如在谷歌上面看一看自己喜欢的电影,\n",
      "--------------------\n",
      "乔布斯曾经说过:“当我最自豪的时候,我不是在做产品,而是在做我想做的事。”乔布斯还说过:“不管我现在做什么,我总是希望将来能做得更好。”在乔布斯\n",
      "--------------------\n",
      "乔布斯曾经说过:“当我进入苹果时,我发现他们(手机)并不是我想要的。我认为手机应该是一个具有特殊性能的产品,应该是我们生活中的一部分。”这句话对产品设计带来了很大的影响,也\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''乔布斯曾经说过：“''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 菜谱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "青椒肉丝的做法:1.将猪肉切成丝,青椒切成细丝,用盐和胡椒粉拌匀,腌制10分钟2.锅内放油,烧至七成热时,将肉丝放入锅中滑炒至变色,盛出\n",
      "--------------------\n",
      "青椒肉丝的做法:1.猪肉切片用料酒,生抽,老抽,淀粉,盐,蛋清抓匀腌制一会2.青椒洗净去籽,切成细丝3.炒锅烧热,下油\n",
      "--------------------\n",
      "青椒肉丝的做法:1.肉丝用盐、酱油、糖、鸡精、淀粉、料酒腌制。青椒洗净去籽,切成细丝。2.锅内倒油,油热后下肉丝翻炒至变色盛出。\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''青椒肉丝的做法：''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圣女果炒茶叶蛋的做法:1.鸡蛋打散,加入适量盐和生粉。<eot>圣女果炒茶叶蛋的做法2.倒入平底锅,炒至鸡蛋变软。<eot>圣女果炒茶叶蛋的做\n",
      "--------------------\n",
      "圣女果炒茶叶蛋的做法:是鸡蛋炒制<eot>圣女果炒茶叶蛋的做法:<eot>圣女果炒茶叶蛋的做法:圣女果炒茶叶蛋的做法:圣女果炒茶叶蛋的做法:圣女果炒茶叶\n",
      "--------------------\n",
      "圣女果炒茶叶蛋的做法:是圣女果洗净,切成小块<eot>圣女果炒茶叶蛋的做法:<eot>圣女果炒茶叶蛋的做法:主料:圣女果10个、茶叶蛋10个配料:葱段、蒜末\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''圣女果炒茶叶蛋的做法：''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国四大发明是哪四大发明\n",
      "造纸术、印刷术、火药、指南针<eot>四大发明分别是指什么呢?一、造纸术造纸术是中国古代四大发明之一,是中国古代劳动人民在总结前人经验的基础上,\n",
      "--------------------\n",
      "中国四大发明是指哪些\n",
      "指南针、造纸术、印刷术、火药<eot>四大发明是指哪些中国四大发明是指中国古代伟大的四大发明。<eot>我的问题是我在网上查的是属于什么版本的游戏呢,\n",
      "--------------------\n",
      "中国四大发明是什么\n",
      "造纸术、印刷术、指南针、火药<eot>2013年,中国有四大发明入选《世界记忆名录》,分别是:造纸术、印刷术、指南针、火药<eot>中国四大发明是什么?<eot>2017\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''中国四大发明是''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "上联:瑞风播福泽,事业昌盛千家乐\n",
      "下联:福泽传忠信,幸福安康四海人<eot>有朋友来家里做客,他怎么说?\n",
      "上联:瑞风播福泽,事业昌盛千家乐下联:福泽传忠信,幸福安康四海人\n",
      "--------------------\n",
      "上联:瑞风播福泽,事业昌盛千家乐\n",
      "下联:福瑞迎春,吉星高照万户欢\n",
      "横批:春满人间\n",
      "福从天降,福从善来,好运是我们永远的追求。让我们从现在开始,用自己的双手去创造美好\n",
      "--------------------\n",
      "上联:瑞风播福泽,事业昌盛千家乐\n",
      "下联:云帆载福临,顺风顺水百业兴\n",
      "横批:福满四海<eot>如何做到快速地记住单词?\n",
      "怎么记住单词的读音?\n",
      "怎么记住单词的意思?\n",
      "怎么\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "ret = sample(\n",
    "    tokenizer, gpt, '''上联：瑞风播福泽，事业昌盛千家乐\n",
    "下联：''',\n",
    "    3, 50, top_k=50, top_p=0.9, temperature=0.9)\n",
    "for x in ret:\n",
    "    print(x)\n",
    "    print('-' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
