{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "from tf2gpt.model import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "1.9.0\n",
      "1.11.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e5c8cbb713fd916b12cbed7fb94a1242  ../pangu-alpha-evolution_2.6B_fp16.zip\r\n"
     ]
    }
   ],
   "source": [
    "# download and unzip from\n",
    "# https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha-Evolution\n",
    "!md5sum ../pangu-alpha-evolution_2.6B_fp16.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9G\t../pangu-alpha-evolution_2.6b_fp16/iter_0055000/mp_rank_00/model_optim_rng.pt\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh ../pangu-alpha-evolution_2.6b_fp16/iter_0055000/mp_rank_00/model_optim_rng.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = torch.load(\n",
    "    '../pangu-alpha-evolution_2.6b_fp16/iter_0055000/mp_rank_00/model_optim_rng.pt',\n",
    "    map_location='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0_weights = []\n",
    "\n",
    "def extract_weight(w = m0['model'], root=''):\n",
    "    for k, v in w.items():\n",
    "        if isinstance(v, dict):\n",
    "            extract_weight(v, root + '.' + k)\n",
    "        elif isinstance(v, torch.Tensor):\n",
    "            k = root + '.' + k\n",
    "            k = k.replace('.language_model.', '')\n",
    "            k = k.replace('.topQueryLayer.', '.layers.31.')\n",
    "            m0_weights.append((\n",
    "                k,\n",
    "                v\n",
    "            ))\n",
    "        else:\n",
    "            print('what?', type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m0_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.word_embeddings.weight torch.Size([40000, 2560])\n",
      "embedding.position_embeddings.weight torch.Size([1024, 2560])\n",
      "transformer.layers.0.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.0.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.0.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.0.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.0.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.0.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.0.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.0.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.0.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.0.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.0.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.0.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.0.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.0.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.0.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.0.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.1.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.1.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.1.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.1.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.1.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.1.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.1.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.1.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.1.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.1.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.1.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.1.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.1.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.1.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.1.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.1.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.2.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.2.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.2.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.2.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.2.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.2.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.2.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.2.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.2.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.2.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.2.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.2.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.2.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.2.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.2.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.2.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.3.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.3.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.3.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.3.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.3.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.3.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.3.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.3.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.3.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.3.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.3.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.3.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.3.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.3.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.3.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.3.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.4.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.4.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.4.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.4.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.4.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.4.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.4.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.4.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.4.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.4.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.4.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.4.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.4.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.4.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.4.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.4.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.5.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.5.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.5.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.5.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.5.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.5.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.5.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.5.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.5.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.5.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.5.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.5.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.5.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.5.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.5.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.5.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.6.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.6.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.6.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.6.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.6.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.6.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.6.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.6.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.6.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.6.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.6.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.6.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.6.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.6.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.6.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.6.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.7.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.7.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.7.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.7.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.7.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.7.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.7.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.7.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.7.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.7.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.7.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.7.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.7.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.7.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.7.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.7.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.8.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.8.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.8.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.8.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.8.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.8.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.8.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.8.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.8.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.8.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.8.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.8.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.8.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.8.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.8.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.8.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.9.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.9.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.9.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.9.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.9.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.9.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.9.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.9.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.9.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.9.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.9.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.9.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.9.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.9.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.9.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.9.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.10.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.10.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.10.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.10.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.10.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.10.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.10.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.10.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.10.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.10.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.10.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.10.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.10.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.10.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.10.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.10.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.11.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.11.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.11.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.11.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.11.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.11.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.11.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.11.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.11.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.11.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.11.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.11.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.11.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.11.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.11.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.11.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.12.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.12.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.12.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.12.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.12.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.12.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.12.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.12.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.12.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.12.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.12.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.12.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.12.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.12.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.12.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.12.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.13.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.13.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.13.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.13.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.13.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.13.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.13.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.13.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.13.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.13.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.13.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.13.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.13.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.13.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.13.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.13.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.14.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.14.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.14.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.14.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.14.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.14.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.14.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.14.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.14.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.14.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.14.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.14.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.14.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.14.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.14.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.14.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.15.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.15.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.15.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.15.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.15.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.15.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.15.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.15.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.15.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.15.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.15.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.15.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.15.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.15.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.15.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.15.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.16.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.16.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.16.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.16.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.16.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.16.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.16.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.16.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.16.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.16.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.16.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.16.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.16.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.16.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.16.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.16.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.17.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.17.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.17.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.17.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.17.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.17.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.17.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.17.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.17.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.17.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.17.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.17.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.17.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.17.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.17.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.17.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.18.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.18.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.18.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.18.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.18.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.18.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.18.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.18.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.18.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.18.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.18.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.18.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.18.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.18.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.18.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.18.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.19.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.19.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.19.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.19.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.19.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.19.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.19.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.19.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.19.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.19.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.19.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.19.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.19.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.19.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.19.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.19.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.20.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.20.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.20.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.20.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.20.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.20.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.20.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.20.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.20.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.20.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.20.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.20.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.20.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.20.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.20.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.20.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.21.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.21.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.21.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.21.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.21.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.21.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.21.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.21.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.21.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.21.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.21.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.21.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.21.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.21.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.21.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.21.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.22.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.22.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.22.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.22.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.22.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.22.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.22.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.22.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.22.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.22.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.22.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.22.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.22.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.22.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.22.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.22.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.23.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.23.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.23.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.23.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.23.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.23.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.23.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.23.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.23.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.23.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.23.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.23.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.23.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.23.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.23.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.23.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.24.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.24.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.24.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.24.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.24.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.24.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.24.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.24.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.24.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.24.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.24.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.24.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.24.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.24.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.24.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.24.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.25.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.25.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.25.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.25.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.25.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.25.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.25.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.25.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.25.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.25.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.25.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.25.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.25.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.25.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.25.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.25.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.26.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.26.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.26.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.26.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.26.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.26.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.26.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.26.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.26.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.26.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.26.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.26.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.26.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.26.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.26.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.26.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.27.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.27.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.27.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.27.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.27.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.27.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.27.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.27.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.27.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.27.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.27.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.27.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.27.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.27.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.27.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.27.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.28.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.28.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.28.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.28.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.28.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.28.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.28.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.28.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.28.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.28.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.28.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.28.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.28.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.28.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.28.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.28.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.29.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.29.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.29.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.29.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.29.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.29.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.29.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.29.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.29.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.29.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.29.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.29.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.29.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.29.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.29.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.29.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.30.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.30.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.30.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.30.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.30.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.30.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.30.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.30.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.30.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.30.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.30.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.30.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.30.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.30.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.30.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.30.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.layers.31.input_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.31.input_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.31.attention.query.weight torch.Size([2560, 2560])\n",
      "transformer.layers.31.attention.query.bias torch.Size([2560])\n",
      "transformer.layers.31.attention.key.weight torch.Size([2560, 2560])\n",
      "transformer.layers.31.attention.key.bias torch.Size([2560])\n",
      "transformer.layers.31.attention.value.weight torch.Size([2560, 2560])\n",
      "transformer.layers.31.attention.value.bias torch.Size([2560])\n",
      "transformer.layers.31.attention.dense.weight torch.Size([2560, 2560])\n",
      "transformer.layers.31.attention.dense.bias torch.Size([2560])\n",
      "transformer.layers.31.post_attention_layernorm.weight torch.Size([2560])\n",
      "transformer.layers.31.post_attention_layernorm.bias torch.Size([2560])\n",
      "transformer.layers.31.mlp.dense_h_to_4h.weight torch.Size([10240, 2560])\n",
      "transformer.layers.31.mlp.dense_h_to_4h.bias torch.Size([10240])\n",
      "transformer.layers.31.mlp.dense_4h_to_h.weight torch.Size([2560, 10240])\n",
      "transformer.layers.31.mlp.dense_4h_to_h.bias torch.Size([2560])\n",
      "transformer.final_layernorm.weight torch.Size([2560])\n",
      "transformer.final_layernorm.bias torch.Size([2560])\n",
      "task_embedding.top_query_embeddings.weight torch.Size([1024, 2560])\n"
     ]
    }
   ],
   "source": [
    "pangu_weights = {}\n",
    "for k, v in m0_weights:\n",
    "    print(k, v.shape)\n",
    "    pangu_weights[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(\n",
    "    vocab_size=40_000,\n",
    "    layer_size=32,\n",
    "    block_size=1024,\n",
    "    embedding_dropout=0.0,\n",
    "    embedding_size=2560,\n",
    "    num_attention_heads=32,\n",
    "    attention_dropout=0.0,\n",
    "    residual_dropout=0.0,\n",
    "    use_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 40000)\n"
     ]
    }
   ],
   "source": [
    "print(gpt(tf.constant([[1]]))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt/embedding/embeddings:0 (40000, 2560)\n",
      "position_embeddings:0 (1024, 2560)\n",
      "top_query:0 (1024, 2560)\n",
      "gpt/layer00/attention/query_layer/kernel:0 (2560, 2560)\n",
      "gpt/layer00/attention/query_layer/bias:0 (2560,)\n",
      "gpt/layer00/attention/key_layer/kernel:0 (2560, 2560)\n",
      "gpt/layer00/attention/key_layer/bias:0 (2560,)\n",
      "gpt/layer00/attention/value_layer/kernel:0 (2560, 2560)\n",
      "gpt/layer00/attention/value_layer/bias:0 (2560,)\n",
      "gpt/layer00/attention/context_projection_layer/kernel:0 (2560, 2560)\n",
      "gpt/layer00/attention/context_projection_layer/bias:0 (2560,)\n",
      "gpt/layer00/LayerNorm_mlp_ln0/gamma:0 (2560,)\n",
      "gpt/layer00/LayerNorm_mlp_ln0/beta:0 (2560,)\n",
      "gpt/layer00/LayerNorm_mlp_ln1/gamma:0 (2560,)\n",
      "gpt/layer00/LayerNorm_mlp_ln1/beta:0 (2560,)\n",
      "gpt/layer00/intermediate/kernel:0 (2560, 10240)\n",
      "gpt/layer00/intermediate/bias:0 (10240,)\n",
      "gpt/layer00/output/kernel:0 (10240, 2560)\n",
      "gpt/layer00/output/bias:0 (2560,)\n",
      "gpt/LayerNorm_final_norm/gamma:0 (2560,)\n",
      "gpt/LayerNorm_final_norm/beta:0 (2560,)\n"
     ]
    }
   ],
   "source": [
    "for x in gpt.weights:\n",
    "    if 'gpt/layer' in x.name:\n",
    "        if 'gpt/layer00' in x.name:\n",
    "            print(x.name, x.shape)\n",
    "    else:\n",
    "        print(x.name, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = []\n",
    "\n",
    "for x in gpt.weights:\n",
    "    xs = tuple(x.shape)\n",
    "\n",
    "    if 'gpt/embedding/embeddings:' in x.name:\n",
    "        pname = 'embedding.word_embeddings.weight'\n",
    "        w = pangu_weights[pname]\n",
    "        assert w.shape == (4_0000, 2560)\n",
    "        new_weights.append((x.name, xs, pname, w))\n",
    "\n",
    "    elif 'position_embeddings' in x.name:\n",
    "        pname = 'embedding.position_embeddings.weight'\n",
    "        w = pangu_weights[pname]\n",
    "        assert xs == w.shape\n",
    "        new_weights.append((x.name, xs, pname, w))\n",
    "    \n",
    "    elif 'top_query' in x.name:\n",
    "        pname = 'task_embedding.top_query_embeddings.weight'\n",
    "        w = pangu_weights[pname]\n",
    "        assert xs == w.shape\n",
    "        new_weights.append((x.name, xs, pname, w))\n",
    "\n",
    "    elif 'gpt/layer' in x.name:\n",
    "        n_layer = int(x.name[len('gpt/layer'):][:2])\n",
    "        if 'query_layer/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.query.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "        elif 'key_layer/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.key.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "        elif 'value_layer/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.value.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "        elif 'query_layer/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.query.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "        elif 'key_layer/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.key.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "        elif 'value_layer/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.value.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert xs == w.shape\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "\n",
    "        elif 'attention/context_projection_layer/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.dense.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "\n",
    "        elif 'attention/context_projection_layer/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.attention.dense.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, xs, pname, w))\n",
    "\n",
    "        elif 'LayerNorm_mlp_ln0/gamma' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.input_layernorm.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif 'LayerNorm_mlp_ln1/gamma' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.post_attention_layernorm.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif 'LayerNorm_mlp_ln0/beta' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.input_layernorm.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif 'LayerNorm_mlp_ln1/beta' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.post_attention_layernorm.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif 'intermediate/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.mlp.dense_h_to_4h.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif 'intermediate/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.mlp.dense_h_to_4h.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif '/output/kernel' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.mlp.dense_4h_to_h.weight'\n",
    "            w = pangu_weights[pname]\n",
    "            w = np.transpose(w)\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        elif '/output/bias' in x.name:\n",
    "            pname = f'transformer.layers.{n_layer}.mlp.dense_4h_to_h.bias'\n",
    "            w = pangu_weights[pname]\n",
    "            assert w.shape == xs\n",
    "            new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "        else:\n",
    "            print('BAD', x.name, xs)\n",
    "            break\n",
    "    elif 'gpt/LayerNorm_final_norm/gamma' in x.name:\n",
    "        pname = 'transformer.final_layernorm.weight'\n",
    "        w = pangu_weights[pname]\n",
    "        assert w.shape == xs\n",
    "        new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "    elif 'gpt/LayerNorm_final_norm/beta' in x.name:\n",
    "        pname = 'transformer.final_layernorm.bias'\n",
    "        w = pangu_weights[pname]\n",
    "        assert w.shape == xs\n",
    "        new_weights.append((x.name, x.shape, pname, w))\n",
    "\n",
    "    else:\n",
    "        print('BAD', x.name, xs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(new_weights) == len(gpt.weights)\n",
    "for x in new_weights:\n",
    "    assert tuple(x[1]) == x[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.set_weights([x[-1] for x in new_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization_jieba import JIEBATokenizer\n",
    "cbpe = JIEBATokenizer(\n",
    "    'PanGu-Alpha-GPU/panguAlpha_pytorch/megatron/tokenizer/bpe_4w_pcl/vocab.vocab',\n",
    "    'PanGu-Alpha-GPU/panguAlpha_pytorch/megatron/tokenizer/bpe_4w_pcl/vocab.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbpe.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.506 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 青椒肉丝的做法:1\n",
      "1 青椒肉丝的做法:1.\n",
      "2 青椒肉丝的做法:1.青\n",
      "3 青椒肉丝的做法:1.青椒\n",
      "4 青椒肉丝的做法:1.青椒洗净\n",
      "5 青椒肉丝的做法:1.青椒洗净切\n",
      "6 青椒肉丝的做法:1.青椒洗净切丝\n",
      "7 青椒肉丝的做法:1.青椒洗净切丝,\n",
      "8 青椒肉丝的做法:1.青椒洗净切丝,肉\n",
      "9 青椒肉丝的做法:1.青椒洗净切丝,肉丝\n"
     ]
    }
   ],
   "source": [
    "ids = cbpe.encode('青椒肉丝的做法：')\n",
    "\n",
    "for i in range(10):\n",
    "    output = gpt(tf.constant([ids]))[0]\n",
    "    nid = np.argmax(output[0, -1])\n",
    "    ids += [int(nid)]\n",
    "    print(i, cbpe.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      ".\n",
      "青\n",
      "椒\n",
      "洗净\n",
      "切\n",
      "丝\n",
      ",\n",
      "肉\n",
      "丝\n",
      "用\n"
     ]
    }
   ],
   "source": [
    "# 模型 + kv模型结合\n",
    "ids = cbpe.encode('青椒肉丝的做法：')\n",
    "\n",
    "logits, kv_cache = gpt(tf.constant([ids]), use_cache=True)\n",
    "nid = np.argmax(logits[0, -1])\n",
    "print(cbpe.decode([int(nid)]))\n",
    "\n",
    "for i in range(10):\n",
    "    logits, kv_cache_new = gpt(tf.constant([[nid]]), kv_cache=kv_cache, use_cache=True)\n",
    "    kv_cache = tf.concat([kv_cache, kv_cache_new], axis=-2)\n",
    "    nid = np.argmax(logits[0, -1])\n",
    "    print(cbpe.decode([int(nid)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算一个初始 kv_cache 作为常量，13是计算出来对模型影响最小的\n",
    "_, kv_cache_start = gpt(tf.constant([[13]]), use_cache=True)\n",
    "np.save('kv_cache', kv_cache_start.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      ".\n",
      "青\n",
      "椒\n",
      "洗净\n",
      "切\n",
      "丝\n",
      ",\n",
      "肉\n",
      "丝\n",
      "用\n"
     ]
    }
   ],
   "source": [
    "# 只用包含kv的模型\n",
    "logits, kv_cache = gpt(tf.constant([ids]), kv_cache=np.load('kv_cache.npy'), use_cache=True)\n",
    "nid = np.argmax(logits[0, -1])\n",
    "print(cbpe.decode([int(nid)]))\n",
    "\n",
    "for i in range(10):\n",
    "    logits, kv_cache_new = gpt(tf.constant([[nid]]), kv_cache=kv_cache, use_cache=True)\n",
    "    kv_cache = tf.concat([kv_cache, kv_cache_new], axis=-2)\n",
    "    nid = np.argmax(logits[0, -1])\n",
    "    print(cbpe.decode([int(nid)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def serve(inputs):\n",
    "    return gpt(inputs, kv_cache=None, use_cache=True)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def serve_cache(inputs, kv_cache):\n",
    "    return gpt(inputs, kv_cache=kv_cache, use_cache=True)\n",
    "\n",
    "serve_concrete = serve.get_concrete_function(\n",
    "    tf.TensorSpec(shape=[None, None], dtype=tf.int64, name=\"inp\")\n",
    ")\n",
    "\n",
    "layer_size = 32\n",
    "attention_head = 32\n",
    "embedding_size = 2560\n",
    "\n",
    "serve_cache_concrete = serve_cache.get_concrete_function(\n",
    "    tf.TensorSpec(shape=[None, None], dtype=tf.int64, name=\"inp\"),\n",
    "    tf.TensorSpec(shape=[\n",
    "        layer_size, None, 2, attention_head,\n",
    "        None, embedding_size // attention_head\n",
    "    ], dtype=tf.float32, name=\"kv_cache\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gpt.save('./pangu-2.6B-tf2', include_optimizer=False, signatures={\n",
    "#     'serving_default': serve.get_concrete_function(\n",
    "#         tf.TensorSpec(shape=[None, None], dtype=tf.int64, name=\"input_ids\"),\n",
    "#     )\n",
    "# })\n",
    "\n",
    "# !rm -rf onnx\n",
    "# !mkdir -p onnx\n",
    "# !python -m tf2onnx.convert \\\n",
    "#     --saved-model pangu-2.6B-tf2 \\\n",
    "#     --output onnx/pangu.zip --large_model --opset=13\n",
    "\n",
    "# !cd onnx && unzip -q pangu.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029ce6c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029c885b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029d35700>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029d200d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029d09b20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f7e29526d30>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029d46880>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802962afd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802963c6a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295c9cd0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295da340>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295e8970>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295f4fa0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029587610>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029593c40>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295a62b0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295b38e0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80295bff10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029551580>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029560bb0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029570220>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029580850>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802950beb0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802951c520>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802952cb50>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802953d1c0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80294cb7f0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80294d6e20>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80294e9490>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f80294f6ac0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f802948a160>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x7f8029495790>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as attention_layer_call_fn, attention_layer_call_and_return_conditional_losses, LayerNorm_mlp_ln0_layer_call_fn, LayerNorm_mlp_ln0_layer_call_and_return_conditional_losses, LayerNorm_mlp_ln1_layer_call_fn while saving (showing 5 of 768). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./pangu-2.6B-tf2-kv/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./pangu-2.6B-tf2-kv/assets\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029cce7f0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029cf3340> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029c88910> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029d2efd0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029d19a00> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029d09370> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029ca11f0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029d46f70> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802962f580> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802963cbb0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295d0220> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295da850> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295e8e80> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295fa4f0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029587b20> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802959b190> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295a67c0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295b3df0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029546460> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029551a90> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029565100> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029570730> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029580d60> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f8029511400> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802951ca30> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80295300a0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802953d6d0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80294cbd00> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80294de370> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80294e99a0> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f80294fd040> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<tf2gpt.model.Attention object at 0x7f802948a670> has the same name 'Attention' as a built-in Keras object. Consider renaming <class 'tf2gpt.model.Attention'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "gpt.save('./pangu-2.6B-tf2-kv', include_optimizer=False, signatures={\n",
    "    'serving_default': serve_cache.get_concrete_function(\n",
    "        tf.TensorSpec(shape=[None, None], dtype=tf.int64, name=\"input_ids\"),\n",
    "        tf.TensorSpec(shape=[\n",
    "            layer_size, None, 2, attention_head,\n",
    "            None, embedding_size // attention_head\n",
    "        ], dtype=tf.float32, name=\"kv_cache\")\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:02:48.268623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "/opt/conda/lib/python3.8/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-05-25 02:02:51.934274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-25 02:02:51.934649: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-25 02:02:52,023 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2022-05-25 02:03:20,770 - INFO - Signatures found in model: [serving_default].\n",
      "2022-05-25 02:03:20,771 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2022-05-25 02:03:20,773 - INFO - Output names: ['output_0', 'output_1']\n",
      "2022-05-25 02:04:13,128 - INFO - Using tensorflow=2.9.0, onnx=1.9.0, tf2onnx=1.10.1/a37f29\n",
      "2022-05-25 02:04:13,129 - INFO - Using opset <onnx, 13>\n",
      "2022-05-25 02:05:44,811 - INFO - Computed 808 values for constant folding\n",
      "2022-05-25 02:06:30,874 - INFO - folding node using tf type=Identity, name=Func/StatefulPartitionedCall/input/_2\n",
      "2022-05-25 02:06:31,663 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/position_embedding_1/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,682 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/position_embedding/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,683 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,683 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,692 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,692 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer00/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,693 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer00/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,693 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,693 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,694 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer00/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,694 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,695 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,695 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,695 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer01/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,696 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer01/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,696 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,701 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,702 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer01/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,703 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,704 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,705 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,706 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer02/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,707 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer02/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,708 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,708 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,709 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer02/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,710 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,711 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,712 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,713 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer03/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,714 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer03/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,715 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,716 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,718 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer03/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,718 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,719 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,720 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,721 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer04/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,722 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer04/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,723 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,724 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,725 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer04/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,725 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,726 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,726 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,726 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer05/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,728 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer05/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,728 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,729 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,730 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer05/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,731 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,732 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,733 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,734 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer06/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,735 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer06/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,736 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,737 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,737 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer06/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,738 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,739 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,740 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,740 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer07/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,741 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer07/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,742 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer07/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,743 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,744 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,744 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,745 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer08/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,745 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer08/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,745 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer08/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,746 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,747 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,748 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer09/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,748 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer09/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,749 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer09/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,750 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,751 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/attention/query_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,751 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer10/attention/strided_slice_2/stack_1\n",
      "2022-05-25 02:06:31,751 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer10/attention/strided_slice_2/stack_2\n",
      "2022-05-25 02:06:31,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/attention/context_projection_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/intermediate/Tensordot/concat\n",
      "2022-05-25 02:06:31,752 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer10/output/Tensordot/concat\n",
      "2022-05-25 02:06:31,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/attention/key_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,753 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/attention/value_layer/Tensordot/concat\n",
      "2022-05-25 02:06:31,754 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/attention/query_layer/Tensordot/concat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:31,757 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer11/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,758 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer11/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,758 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer11/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,759 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,760 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,761 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,761 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer12/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,762 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer12/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,763 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,763 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,764 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer12/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,764 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,765 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,765 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,766 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer13/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,766 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer13/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,766 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,766 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,767 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer13/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,767 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,768 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,768 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,768 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer14/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,769 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer14/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,769 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,769 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,770 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer14/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,770 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,770 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,771 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,771 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer15/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,771 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer15/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,771 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,772 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,772 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer15/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,772 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,773 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,773 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,773 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer16/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,774 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer16/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,774 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,774 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,775 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer16/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,775 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,775 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,776 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,776 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer17/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,776 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer17/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,777 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,777 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,777 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer17/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,777 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,778 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,778 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,778 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer18/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,779 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer18/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,779 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,779 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,780 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer18/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,780 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,780 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,781 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,781 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer19/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,781 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer19/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,782 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,783 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,783 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer19/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,784 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,785 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,785 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,786 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer20/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,787 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer20/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,788 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,788 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,789 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer20/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,790 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,790 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,790 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,791 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer21/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,791 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer21/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,791 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,792 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,792 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer21/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,792 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,793 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,793 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,793 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer22/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,794 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer22/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,794 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,794 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,795 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer22/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,795 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,795 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,796 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,796 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer23/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,796 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer23/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,797 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,797 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,798 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer23/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,798 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,798 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,799 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,799 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer24/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,799 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer24/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,800 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,800 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,800 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer24/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,801 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,801 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,801 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,801 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer25/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,802 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer25/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,802 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,802 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,803 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer25/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,803 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,803 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,804 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,804 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer26/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,804 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer26/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,804 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,805 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,805 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer26/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,806 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,806 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,807 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,807 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer27/attention/strided_slice_2/stack_1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:31,809 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer27/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,809 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,810 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,810 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer27/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,811 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,811 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,812 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,812 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer28/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,812 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer28/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,813 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,813 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,813 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer28/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,814 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,814 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,814 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,815 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer29/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,815 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer29/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,815 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,816 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,816 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer29/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,816 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,817 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,817 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,818 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer30/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,818 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer30/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,818 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,819 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,819 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer30/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,820 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/attention/key_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,820 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/attention/value_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,820 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/attention/query_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,821 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer31/attention/strided_slice_2/stack_1\r\n",
      "2022-05-25 02:06:31,821 - INFO - folding node using tf type=Pack, name=StatefulPartitionedCall/gpt/layer31/attention/strided_slice_2/stack_2\r\n",
      "2022-05-25 02:06:31,822 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/attention/context_projection_layer/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,822 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/intermediate/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,822 - INFO - folding node using tf type=ConcatV2, name=StatefulPartitionedCall/gpt/layer31/output/Tensordot/concat\r\n",
      "2022-05-25 02:06:31,823 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer00/activation/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,823 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer01/activation_1/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,823 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer02/activation_2/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,824 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer03/activation_3/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,824 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer04/activation_4/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,825 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer05/activation_5/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,825 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer06/activation_6/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,825 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer07/activation_7/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,826 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer08/activation_8/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,826 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer09/activation_9/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,827 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer10/activation_10/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,827 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer11/activation_11/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,827 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer12/activation_12/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,828 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer13/activation_13/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,828 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer14/activation_14/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,828 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer15/activation_15/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,829 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer16/activation_16/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,829 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer17/activation_17/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,829 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer18/activation_18/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,830 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer19/activation_19/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,830 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer20/activation_20/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,831 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer21/activation_21/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,831 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer22/activation_22/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,831 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer23/activation_23/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,832 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer24/activation_24/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,832 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer25/activation_25/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,832 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer26/activation_26/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,833 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer27/activation_27/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,833 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer28/activation_28/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,833 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer29/activation_29/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,834 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer30/activation_30/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,834 - INFO - folding node using tf type=Sqrt, name=StatefulPartitionedCall/gpt/layer31/activation_31/PartitionedCall/Sqrt\r\n",
      "2022-05-25 02:06:31,835 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/position_embedding_1/ReadVariableOp\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:31,874 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/position_embedding/ReadVariableOp\n",
      "2022-05-25 02:06:31,894 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:31,894 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:31,895 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:32,072 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:32,073 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:32,148 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:32,149 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:32,225 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:32,226 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:32,316 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:32,318 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:32,319 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:32,320 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:32,853 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:32,855 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:33,599 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer00/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:33,601 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:33,603 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:33,604 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:33,717 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:33,717 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:33,786 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:33,787 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:33,887 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:33,887 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:33,987 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:33,989 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:33,989 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:33,990 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:34,753 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:34,753 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,073 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer01/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,074 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:35,074 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:35,074 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,139 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,149 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,207 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,208 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,267 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,269 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,324 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,324 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:35,325 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:35,325 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:35,752 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:35,753 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:36,190 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer02/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,191 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:36,192 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:36,193 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:36,263 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,264 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/value_layer/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:36,326 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,326 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:36,383 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,384 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:36,444 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,444 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:36,445 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:36,445 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:36,866 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:36,868 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:37,467 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer03/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:37,470 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:37,471 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:37,471 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:37,570 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:37,572 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:37,648 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:37,649 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:37,722 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:37,723 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:37,780 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:37,780 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:37,780 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:37,781 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,185 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,186 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,471 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer04/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,472 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:38,472 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:38,472 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,512 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,513 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,553 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,554 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,596 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,596 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,640 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,640 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:38,641 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:38,641 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:38,981 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:38,983 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:39,312 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer05/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:39,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:39,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:39,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:39,362 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:39,362 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:39,404 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:39,408 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:39,485 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:39,486 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:39,555 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:39,556 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:39,557 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:39,558 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/intermediate/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:40,143 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,143 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:40,533 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer06/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,534 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:40,535 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:40,536 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:40,578 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,579 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:40,619 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,620 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:40,658 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,658 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:40,709 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:40,710 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:40,710 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:40,711 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,015 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,016 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer07/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:41,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:41,314 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,351 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,352 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,387 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,388 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,422 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,423 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,458 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,459 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:41,459 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:41,460 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:41,777 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:41,777 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:42,119 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer08/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:42,119 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:42,120 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:42,120 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:42,158 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:42,159 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:42,201 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:42,202 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:42,240 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:42,241 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:42,279 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:42,280 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:42,280 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:42,281 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:43,308 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:43,308 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:44,435 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer09/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:44,439 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:44,449 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:44,451 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/key_layer/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:44,620 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:44,627 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:44,771 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:44,796 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:44,924 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:44,924 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:45,058 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:45,059 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:45,059 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:45,081 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:46,137 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:46,150 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:47,350 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer10/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:47,361 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:47,364 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:47,366 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:47,494 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:47,514 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:47,639 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:47,674 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:47,823 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:47,845 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:47,987 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:48,015 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:48,018 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:48,020 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:48,554 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:48,554 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:49,279 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer11/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:49,279 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:49,280 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:49,280 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:49,392 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:49,404 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:49,519 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:49,529 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:49,679 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:49,704 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:49,817 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:49,818 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:49,820 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:49,821 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:50,622 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:50,623 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:51,409 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer12/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:51,422 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:51,424 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:51,425 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:51,486 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:51,505 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:51,560 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:51,569 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:51,667 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:51,668 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/context_projection_layer/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:51,720 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:51,720 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:51,720 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:51,721 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,024 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,025 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,307 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer13/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,308 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:52,309 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:52,310 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,348 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,349 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,386 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,387 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,434 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,434 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,482 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,482 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:52,483 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:52,484 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:52,929 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:52,930 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,189 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer14/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,189 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:53,189 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:53,189 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,218 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,218 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,246 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,246 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,276 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,277 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,352 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,355 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:53,356 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:53,357 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:53,872 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:53,873 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:54,334 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer15/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:54,334 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:54,335 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:54,335 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:54,382 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:54,382 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:54,439 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:54,441 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:54,499 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:54,500 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:54,562 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:54,564 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:54,565 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:54,566 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:55,018 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,020 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/output/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:06:55,526 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer16/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,527 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:55,528 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:55,528 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:55,605 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,607 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:55,681 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,682 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:55,757 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,758 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:55,829 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:55,830 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:55,831 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:55,832 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:56,364 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:56,365 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:57,119 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer17/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:57,120 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:57,120 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:57,124 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:57,250 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:57,253 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:57,349 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:57,363 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:57,464 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:57,471 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:57,582 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:57,584 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:57,585 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:57,586 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:58,314 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:58,318 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:58,931 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer18/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:58,932 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:58,932 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:58,932 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:59,027 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:59,034 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:59,145 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:59,155 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:59,237 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:59,242 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:59,299 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:59,310 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:06:59,312 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:06:59,313 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:06:59,951 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:06:59,956 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:00,621 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer19/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:00,622 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:00,624 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:00,625 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:00,707 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/key_layer/BiasAdd/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:07:00,707 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:00,817 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:00,818 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:00,921 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:00,922 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:01,085 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:01,086 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:01,087 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:01,087 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,035 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,037 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,438 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer20/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,438 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:02,438 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:02,439 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,478 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,479 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,530 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,531 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,611 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,611 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:02,656 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:02,657 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:02,657 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:02,658 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,029 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,031 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,492 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer21/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,493 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:03,494 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:03,495 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,539 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,540 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,614 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,615 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,698 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,699 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:03,783 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:03,783 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:03,784 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:03,785 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:04,204 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:04,209 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:04,897 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer22/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:04,899 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:04,900 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:04,901 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:04,968 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:04,969 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,013 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,014 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,055 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,056 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/context_projection_layer/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:07:05,099 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,099 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:05,100 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:05,101 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,432 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,433 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,914 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer23/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,915 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:05,915 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:05,916 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,953 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,954 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:05,990 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:05,996 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:06,080 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:06,080 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:06,173 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:06,173 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:06,176 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:06,177 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:06,720 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:06,724 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,237 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer24/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,241 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:07,242 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:07,247 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,323 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,332 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,393 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,394 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,430 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,431 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,465 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,466 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:07,467 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:07,467 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:07,967 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:07,971 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:08,503 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer25/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:08,507 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:08,508 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:08,509 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:08,600 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:08,600 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:08,689 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:08,690 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:08,771 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:08,772 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:08,857 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:08,858 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:08,859 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:08,860 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:09,454 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:09,458 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/output/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:07:09,953 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer26/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:09,954 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:09,955 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:09,955 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:09,991 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:09,992 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,029 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,029 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,066 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,067 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,101 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,102 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:10,103 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:10,103 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,547 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,548 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,919 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer27/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,920 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:10,921 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:10,921 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:10,980 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:10,981 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:11,029 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:11,030 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:11,079 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:11,080 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:11,135 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:11,136 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:11,137 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:11,138 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:11,575 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:11,576 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,001 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer28/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,001 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:12,001 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:12,002 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,038 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,038 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,076 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,076 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,108 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,108 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,136 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,136 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:12,136 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:12,137 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,399 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,400 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,653 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer29/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,654 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:12,654 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:12,654 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,694 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,694 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/value_layer/Tensordot/ReadVariableOp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25 02:07:12,738 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,739 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,784 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,784 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:12,826 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:12,826 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:12,826 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:12,826 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,097 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,097 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,374 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer30/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,374 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/LayerNorm_final_norm/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:13,375 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/LayerNorm_final_norm/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:13,375 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/LayerNorm_mlp_ln0/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:13,375 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/LayerNorm_mlp_ln0/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:13,375 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/key_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,415 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/key_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,416 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/value_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,454 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/value_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,455 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/query_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,498 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/query_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,498 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/context_projection_layer/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,540 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/attention/context_projection_layer/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,540 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/LayerNorm_mlp_ln1/batchnorm/mul/ReadVariableOp\n",
      "2022-05-25 02:07:13,540 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/LayerNorm_mlp_ln1/batchnorm/ReadVariableOp\n",
      "2022-05-25 02:07:13,541 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/intermediate/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:13,789 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/intermediate/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:13,790 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/output/Tensordot/ReadVariableOp\n",
      "2022-05-25 02:07:14,053 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/layer31/output/BiasAdd/ReadVariableOp\n",
      "2022-05-25 02:07:14,054 - INFO - folding node using tf type=Identity, name=StatefulPartitionedCall/gpt/Identity\n",
      "2022-05-25 02:07:22,231 - INFO - Optimizing ONNX model\n",
      "2022-05-25 02:09:57,721 - INFO - After optimization: Add -1 (421->420), And -34 (36->2), Cast -518 (940->422), Concat -321 (677->356), Const -5224 (5800->576), Equal -1 (2->1), Gather -255 (385->130), GlobalAveragePool +130 (0->130), Identity -240 (240->0), Less -35 (36->1), Max -1 (2->1), ReduceMean -130 (130->0), ReduceProd -384 (384->0), Reshape -129 (610->481), Shape -97 (292->195), Slice -2 (198->196), Squeeze -34 (164->130), Transpose -193 (353->160), Unsqueeze -934 (1162->228), Where -2 (36->34)\n",
      "2022-05-25 02:10:18,004 - INFO - \n",
      "2022-05-25 02:10:18,004 - INFO - Successfully converted TensorFlow model pangu-2.6B-tf2-kv to ONNX\n",
      "2022-05-25 02:10:18,004 - INFO - Model inputs: ['input_ids', 'kv_cache']\n",
      "2022-05-25 02:10:18,004 - INFO - Model outputs: ['output_0', 'output_1']\n",
      "2022-05-25 02:10:18,004 - INFO - Zipped ONNX model is saved at onnx_kv/pangu.zip. Unzip before opening in onnxruntime.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf onnx_kv\n",
    "!mkdir -p onnx_kv\n",
    "!python -m tf2onnx.convert \\\n",
    "    --saved-model pangu-2.6B-tf2-kv \\\n",
    "    --output onnx_kv/pangu.zip --large_model --opset=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd onnx_kv && unzip -q pangu.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf onnx_q && mkdir -p onnx_q\n",
    "# quantized_model = quantize_dynamic(\n",
    "#     './onnx/__MODEL_PROTO.onnx',\n",
    "#     './onnx_q/pangu.onnx',\n",
    "#     weight_type=QuantType.QUInt8,\n",
    "#     use_external_data_format=True,\n",
    "#     extra_options={\n",
    "#         'DisableShapeInference': True,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer00/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer00/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer01/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer01/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer02/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer02/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer03/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer03/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer04/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer04/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer05/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer05/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer06/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer06/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer07/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer07/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer08/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer08/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer09/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer09/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer10/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer10/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer11/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer11/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer12/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer12/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer13/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer13/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer14/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer14/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer15/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer15/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer16/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer16/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer17/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer17/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer18/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer18/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer19/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer19/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer20/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer20/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer21/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer21/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer22/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer22/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer23/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer23/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer24/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer24/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer25/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer25/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer26/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer26/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer27/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer27/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer28/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer28/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer29/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer29/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer30/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer30/attention/MatMul_1]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer31/attention/MatMul]\n",
      "Ignore MatMul due to non constant B: /[StatefulPartitionedCall/gpt/layer31/attention/MatMul_1]\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/microsoft/onnxruntime/issues/7017#issuecomment-900716895\n",
    "# https://github.com/microsoft/onnxruntime/blob/60089f7093e4e26f837be4bbf74d38cb97b43e4b/onnxruntime/python/tools/quantization/quantize.py#L189\n",
    "!rm -rf onnx_kv_q && mkdir -p onnx_kv_q\n",
    "quantized_model = quantize_dynamic(\n",
    "    './onnx_kv/__MODEL_PROTO.onnx',\n",
    "    './onnx_kv_q/pangu.onnx',\n",
    "    weight_type=QuantType.QUInt8,\n",
    "    use_external_data_format=True,\n",
    "    extra_options={\n",
    "        'DisableShapeInference': True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf onnx\n",
    "!rm -rf onnx_kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf pangu-2.6B-tf2-kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
